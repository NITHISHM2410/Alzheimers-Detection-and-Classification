{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GT1IKxWs7J_9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import glob\n",
        "import re\n",
        "import shutil\n",
        "import random\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/FewShot/final_weights_5.zip\" -d \"/content/weights/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqcV13NUTxV6",
        "outputId": "e71f272e-bfe8-4132-ff24-593df4c36ce0"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/FewShot/final_weights_5.zip\n",
            "replace /content/weights/best_one.data-00000-of-00001? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: /content/weights/best_one.data-00000-of-00001  \n",
            "  inflating: /content/weights/checkpoint  \n",
            "  inflating: /content/weights/best_one.index  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title loading the model (or directly load the architecture)\n",
        "class SQD(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(SQD, self).__init__()\n",
        "    def call(self, inputs):\n",
        "        x, y = inputs\n",
        "        diff = tf.subtract(x, y)\n",
        "        return tf.square(diff)\n",
        "\n",
        "def wave_downsample():\n",
        "    input = tf.keras.Input(batch_size = batch_size,shape = (1024,19))\n",
        "    output = tf.keras.layers.LSTM(10,return_sequences = True)(input)\n",
        "    output = tf.keras.layers.Dense(2)(output)\n",
        "    output = tf.keras.layers.Flatten()(output)\n",
        "    output = tf.keras.layers.Activation('relu')(output)\n",
        "    output = tf.keras.layers.Dropout(0.3)(output)\n",
        "    output = tf.keras.layers.Dense(20)(output)\n",
        "    output = tf.keras.layers.Dropout(0.1)(output)\n",
        "    model = tf.keras.Model(inputs = [input],outputs = [output])\n",
        "    return model\n",
        "     \n",
        "def get_model():\n",
        "    wave1 = tf.keras.Input(batch_size = batch_size,shape = (1024,19),name = 'wave1')\n",
        "    wave2 = tf.keras.Input(batch_size = batch_size,shape = (1024,19),name = 'wave2')\n",
        "    state = tf.keras.Input(batch_size = batch_size,shape = (2,),name = 'state')\n",
        "    \n",
        "    output1 = tf.keras.layers.BatchNormalization()(wave1)\n",
        "    output2 = tf.keras.layers.BatchNormalization()(wave2)\n",
        "\n",
        "    down_sampler = wave_downsample()\n",
        "    output1 = down_sampler(output1)\n",
        "    output2 = down_sampler(output2)\n",
        "\n",
        "    output1 = tf.keras.layers.Activation('tanh')(output1)\n",
        "    output1 = tf.keras.layers.Dropout(0.3)(output1)\n",
        "\n",
        "    output2 = tf.keras.layers.Activation('tanh')(output2)\n",
        "    output2 = tf.keras.layers.Dropout(0.3)(output2)\n",
        "\n",
        "    output = SQD()([output1,output2])\n",
        "    output = tf.keras.layers.concatenate([output,state])\n",
        "    output = tf.keras.layers.Dense(10)(output)\n",
        "    output = tf.keras.layers.Dropout(0.2)(output)\n",
        "    output = tf.keras.layers.Dense(1,activation = 'sigmoid',name = 'difference' )(output)\n",
        "    \n",
        "    model = tf.keras.Model(inputs = [wave1,wave2,state],outputs = [output],name = 'FewShot')\n",
        "    return model\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = ['acc'])\n",
        "\n",
        "model = get_model()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "2P61u2xmfFF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(\"/content/weights/best_one\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceTMuW-ndcco",
        "outputId": "dc8aa974-e102-4f92-bb57-73e9b203aad9"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f1382e26950>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaning data for testing"
      ],
      "metadata": {
        "id": "eBZZdCOzPfS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/FINAL_DATASET.zip\""
      ],
      "metadata": {
        "id": "-_w4VrxkPe8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = glob.glob(\"/content/Dataset/*/*\")\n",
        "files"
      ],
      "metadata": {
        "id": "chP1TpWFPoVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean(path):\n",
        "    df = pd.read_csv(path)\n",
        "    \n",
        "    for column in df.columns:\n",
        "        if df[column].dtype == 'object':\n",
        "            print(\"Sample : \",path,\" feature : \",column,\" is uncleaned\")\n",
        "            df[column] = pd.to_numeric(df[column], errors='coerce')\n",
        "            df[column] = df[column].fillna(method='ffill')\n",
        "            df[column] = df[column].fillna(method='bfill')\n",
        "    df = df.iloc[:1024,:]\n",
        "\n",
        "    while df.isnull().sum().values.sum() != 0:\n",
        "        print(\"Sample : \",path,\"getting cleaned\")\n",
        "        df = df.fillna(method = 'ffill')\n",
        "        df = df.fillna(method = 'bfill')\n",
        "    df.to_csv(path, index=False)\n",
        "     \n",
        "for i in files:\n",
        "    clean(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VO4V5cPYPMrD",
        "outputId": "4b59ca64-081c-4ef0-c535-795fb0c0b207"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample :  /content/Dataset/SETA/healthy_open2.csv  feature :  16  is uncleaned\n",
            "Sample :  /content/Dataset/SETA/healthy_open11.csv  feature :  14  is uncleaned\n",
            "Sample :  /content/Dataset/SETC/alzeimer_open5.csv  feature :  0  is uncleaned\n",
            "Sample :  /content/Dataset/SETC/alzeimer_open5.csv getting cleaned\n",
            "Sample :  /content/Dataset/SETC/alzeimer_open8.csv  feature :  0  is uncleaned\n",
            "Sample :  /content/Dataset/SETC/alzeimer_open8.csv getting cleaned\n",
            "Sample :  /content/Dataset/SETC/alzeimer_open6.csv  feature :  0  is uncleaned\n",
            "Sample :  /content/Dataset/SETC/alzeimer_open6.csv getting cleaned\n",
            "Sample :  /content/Dataset/SETC/alzeimer_open10.csv  feature :  0  is uncleaned\n",
            "Sample :  /content/Dataset/SETC/alzeimer_open10.csv getting cleaned\n",
            "Sample :  /content/Dataset/SETD/alzeimer_closed12.csv  feature :  18  is uncleaned\n",
            "Sample :  /content/Dataset/SETB/healthy_closed2.csv  feature :  16  is uncleaned\n",
            "Sample :  /content/Dataset/SETB/healthy_closed6.csv  feature :  14  is uncleaned\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***TESTING TECHNIQUE*** : We will have a query sample of UNKNOWN CLASS which we need to predict as Healthy sample or Alzheimer sample. The query sample will be compared against stored reference samples of healthy and Alzheimer samples with the Similarity Few Shot NN trained. The intended results are: \n",
        "\n",
        "\n",
        "*   Query Sample belongs to 'Alzheimer' class if Similarity score between query sample and Alzheimer reference samples are closer to zero.\n",
        "*   Query Sample belongs to 'Healthy' class if Similarity score between query sample and healthy reference samples are closer to zero.\n",
        "\n"
      ],
      "metadata": {
        "id": "Pzw50N-MQAE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reference = [] # For Comparing Against\n",
        "query = [] # Query Samples for Detection\n",
        "for i in range(0,48,12):\n",
        "    reference += files[i:i+11]\n",
        "    query += files[i+11:i+12]"
      ],
      "metadata": {
        "id": "VMjNkCWlP0Pr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "healthy = []\n",
        "alz = []\n",
        "for afile in reference:\n",
        "    if \"healthy\" in afile:\n",
        "        healthy.append(afile)\n",
        "    elif \"alzeimer\" in afile:\n",
        "        alz.append(afile)    "
      ],
      "metadata": {
        "id": "GVYiYBD6SsXm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query Samples We will be testing are :"
      ],
      "metadata": {
        "id": "q3pRsFrSShRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nrPTioxSLLZ",
        "outputId": "0fd9374f-8eea-4a0d-a4e7-a4d07f48115c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/Dataset/SETA/healthy_open11.csv',\n",
              " '/content/Dataset/SETC/alzeimer_open7.csv',\n",
              " '/content/Dataset/SETD/alzeimer_closed8.csv',\n",
              " '/content/Dataset/SETB/healthy_closed1.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading a sample"
      ],
      "metadata": {
        "id": "ew26guUUdhwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_numeric(csv):\n",
        "    data = pd.read_csv(csv).values\n",
        "    return data\n",
        "\n",
        "def pair_up(x1,x2):\n",
        "        sample = [x1,x2]\n",
        "        if \"closed\" in x1:\n",
        "            sample.append(0)\n",
        "        elif \"open\" in x1:\n",
        "            sample.append(1) \n",
        "        if \"closed\" in x2:\n",
        "            sample.append(0)\n",
        "        elif \"open\" in x2:\n",
        "            sample.append(1)     \n",
        "\n",
        "        sample[0] = to_numeric(x1)\n",
        "        sample[1] = to_numeric(x2)\n",
        "\n",
        "        return sample "
      ],
      "metadata": {
        "id": "6Se4uU1ZTeun"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting Sample ready for Model Input"
      ],
      "metadata": {
        "id": "TziQRAFpdk_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def as_input(sample):\n",
        "    input = dict()\n",
        "    input['wave1'] = tf.cast(tf.expand_dims(sample[0],0),dtype = tf.float32)\n",
        "    input['wave2'] = tf.cast(tf.expand_dims(sample[1],0),dtype = tf.float32)\n",
        "    input['state'] = tf.cast(tf.expand_dims([sample[2],sample[3]],0),dtype = tf.float32)\n",
        "    return input"
      ],
      "metadata": {
        "id": "F-rkGk7gWURy"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TESTING "
      ],
      "metadata": {
        "id": "PCcddBghdrOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_scores(afile):\n",
        "    print(\"Query Sample :\",afile)\n",
        "\n",
        "    healthy_scores = []\n",
        "    alz_scores = []\n",
        "\n",
        "    reference_tests = 3 #No of times to compare \n",
        "\n",
        "    for ref in alz[:reference_tests]:\n",
        "        pair = pair_up(afile,ref)\n",
        "        pair = as_input(pair)\n",
        "        output = np.squeeze(model(pair))\n",
        "        alz_scores.append(output)\n",
        "        \n",
        "    for ref in healthy[:reference_tests]:\n",
        "        pair = pair_up(afile,ref)\n",
        "        pair = as_input(pair)\n",
        "        output = np.squeeze(model(pair))\n",
        "        healthy_scores.append(output)\n",
        "    a_avg,h_avg = sum(alz_scores)/3,sum(healthy_scores)/3\n",
        "    if a_avg > h_avg:\n",
        "        print(\"Query Sample Class Predicted : Healthy Sample\")\n",
        "    else:\n",
        "        print(\"Query Sample Class Predicted : Alzheimer Sample\")    "
      ],
      "metadata": {
        "id": "jdUcFcQzSmjV"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for que in query:\n",
        "    print(\"-----------------------------------------------------------------\")\n",
        "    get_scores(que)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NxRHnKjbjkN",
        "outputId": "a511e27b-3c61-465e-e972-dcc9da57758b"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------\n",
            "Query Sample : /content/Dataset/SETA/healthy_open11.csv\n",
            "Query Sample Class Predicted : Healthy Sample\n",
            "-----------------------------------------------------------------\n",
            "Query Sample : /content/Dataset/SETC/alzeimer_open7.csv\n",
            "Query Sample Class Predicted : Alzheimer Sample\n",
            "-----------------------------------------------------------------\n",
            "Query Sample : /content/Dataset/SETD/alzeimer_closed8.csv\n",
            "Query Sample Class Predicted : Alzheimer Sample\n",
            "-----------------------------------------------------------------\n",
            "Query Sample : /content/Dataset/SETB/healthy_closed1.csv\n",
            "Query Sample Class Predicted : Healthy Sample\n"
          ]
        }
      ]
    }
  ]
}
