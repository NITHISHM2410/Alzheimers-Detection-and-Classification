{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GT1IKxWs7J_9",
        "outputId": "8120badb-f809-45b5-8981-255b86196867",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.20.0 typeguard-2.13.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import glob\n",
        "import re\n",
        "import shutil\n",
        "import random\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install tensorflow_addons\n",
        "import tensorflow_addons as tfa"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wcYu0JkZ-nHS",
        "outputId": "82873e1a-bf20-422b-a133-ccadc6e2db7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/FewShot/final_weights_best.zip\" -d \"/content/weights/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqcV13NUTxV6",
        "outputId": "f64ed05e-446d-489e-993a-3ad9b2e50c16"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/FewShot/final_weights_best.zip\n",
            "  inflating: /content/weights/checkpoint  \n",
            "  inflating: /content/weights/best_one.index  \n",
            "  inflating: /content/weights/best_one.data-00000-of-00001  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOAD THE MODEL"
      ],
      "metadata": {
        "id": "L1N4g41X4SfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "class SQD(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(SQD, self).__init__()\n",
        "    def call(self, inputs):\n",
        "        x, y = inputs\n",
        "        diff = tf.subtract(x, y)\n",
        "        return tf.square(diff)\n",
        "\n",
        "def wave_downsample():\n",
        "    input = tf.keras.Input(batch_size = batch_size,shape = (1024,19))\n",
        "    output = tf.keras.layers.LSTM(10,return_sequences = True)(input)\n",
        "    output = tf.keras.layers.Dense(2)(output)\n",
        "    output = tf.keras.layers.Flatten()(output)\n",
        "    output = tf.keras.layers.Activation('relu')(output)\n",
        "    output = tf.keras.layers.Dropout(0.3)(output)\n",
        "    output = tf.keras.layers.Dense(20)(output)\n",
        "    output = tf.keras.layers.Dropout(0.1)(output)\n",
        "    model = tf.keras.Model(inputs = [input],outputs = [output])\n",
        "    return model\n",
        "     \n",
        "def get_model():\n",
        "    wave1 = tf.keras.Input(batch_size = batch_size,shape = (1024,19),name = 'wave1')\n",
        "    wave2 = tf.keras.Input(batch_size = batch_size,shape = (1024,19),name = 'wave2')\n",
        "    state = tf.keras.Input(batch_size = batch_size,shape = (2,),name = 'state')\n",
        "    \n",
        "    output1 = tf.keras.layers.BatchNormalization()(wave1)\n",
        "    output2 = tf.keras.layers.BatchNormalization()(wave2)\n",
        "\n",
        "    down_sampler = wave_downsample()\n",
        "    output1 = down_sampler(output1)\n",
        "    output2 = down_sampler(output2)\n",
        "\n",
        "    output1 = tf.keras.layers.Activation('tanh')(output1)\n",
        "    output1 = tf.keras.layers.Dropout(0.3)(output1)\n",
        "\n",
        "    output2 = tf.keras.layers.Activation('tanh')(output2)\n",
        "    output2 = tf.keras.layers.Dropout(0.3)(output2)\n",
        "\n",
        "    output = SQD()([output1,output2])\n",
        "    output = tf.keras.layers.concatenate([output,state])\n",
        "    output = tf.keras.layers.Dense(10)(output)\n",
        "    output = tf.keras.layers.Dropout(0.2)(output)\n",
        "    output = tf.keras.layers.Dense(1,activation = 'sigmoid',name = 'difference' )(output)\n",
        "    \n",
        "    model = tf.keras.Model(inputs = [wave1,wave2,state],outputs = [output],name = 'FewShot')\n",
        "    return model\n",
        "\n",
        "model = get_model()\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.000001),\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = [tf.keras.metrics.BinaryAccuracy(threshold=0.8),\n",
        "                         tfa.metrics.F1Score(num_classes=1,threshold = 0.8)])"
      ],
      "metadata": {
        "id": "pKKCNOSX-tyX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(\"/content/weights/best_one\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceTMuW-ndcco",
        "outputId": "f7fb9c93-9718-4550-f9d6-483335c40462"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7ff65c201330>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaning data for testing"
      ],
      "metadata": {
        "id": "eBZZdCOzPfS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/FINAL_DATASET.zip\""
      ],
      "metadata": {
        "id": "-_w4VrxkPe8g",
        "outputId": "29cb9976-a928-412b-a4c3-6ea9af58b3d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/FINAL_DATASET.zip\n",
            "   creating: Dataset/SETA/\n",
            "  inflating: Dataset/SETA/healthy_open1.csv  \n",
            "  inflating: Dataset/SETA/healthy_open10.csv  \n",
            "  inflating: Dataset/SETA/healthy_open11.csv  \n",
            "  inflating: Dataset/SETA/healthy_open12.csv  \n",
            "  inflating: Dataset/SETA/healthy_open2.csv  \n",
            "  inflating: Dataset/SETA/healthy_open3.csv  \n",
            "  inflating: Dataset/SETA/healthy_open4.csv  \n",
            "  inflating: Dataset/SETA/healthy_open5.csv  \n",
            "  inflating: Dataset/SETA/healthy_open6.csv  \n",
            "  inflating: Dataset/SETA/healthy_open7.csv  \n",
            "  inflating: Dataset/SETA/healthy_open8.csv  \n",
            "  inflating: Dataset/SETA/healthy_open9.csv  \n",
            "   creating: Dataset/SETB/\n",
            "  inflating: Dataset/SETB/healthy_closed1.csv  \n",
            "  inflating: Dataset/SETB/healthy_closed10.csv  \n",
            "  inflating: Dataset/SETB/healthy_closed11.csv  \n",
            "  inflating: Dataset/SETB/healthy_closed12.csv  \n",
            "  inflating: Dataset/SETB/healthy_closed2.csv  \n",
            "  inflating: Dataset/SETB/healthy_closed3.csv  \n",
            "  inflating: Dataset/SETB/healthy_closed4.csv  \n",
            "  inflating: Dataset/SETB/healthy_closed5.csv  \n",
            "  inflating: Dataset/SETB/healthy_closed6.csv  \n",
            "  inflating: Dataset/SETB/healthy_closed7.csv  \n",
            "  inflating: Dataset/SETB/healthy_closed8.csv  \n",
            "  inflating: Dataset/SETB/healthy_closed9.csv  \n",
            "   creating: Dataset/SETC/\n",
            "  inflating: Dataset/SETC/alzeimer_open1.csv  \n",
            "  inflating: Dataset/SETC/alzeimer_open10.csv  \n",
            "  inflating: Dataset/SETC/alzeimer_open11.csv  \n",
            "  inflating: Dataset/SETC/alzeimer_open12.csv  \n",
            "  inflating: Dataset/SETC/alzeimer_open2.csv  \n",
            "  inflating: Dataset/SETC/alzeimer_open3.csv  \n",
            "  inflating: Dataset/SETC/alzeimer_open4.csv  \n",
            "  inflating: Dataset/SETC/alzeimer_open5.csv  \n",
            "  inflating: Dataset/SETC/alzeimer_open6.csv  \n",
            "  inflating: Dataset/SETC/alzeimer_open7.csv  \n",
            "  inflating: Dataset/SETC/alzeimer_open8.csv  \n",
            "  inflating: Dataset/SETC/alzeimer_open9.csv  \n",
            "   creating: Dataset/SETD/\n",
            "  inflating: Dataset/SETD/alzeimer_closed1.csv  \n",
            "  inflating: Dataset/SETD/alzeimer_closed10.csv  \n",
            "  inflating: Dataset/SETD/alzeimer_closed11.csv  \n",
            "  inflating: Dataset/SETD/alzeimer_closed12.csv  \n",
            "  inflating: Dataset/SETD/alzeimer_closed2.csv  \n",
            "  inflating: Dataset/SETD/alzeimer_closed3.csv  \n",
            "  inflating: Dataset/SETD/alzeimer_closed4.csv  \n",
            "  inflating: Dataset/SETD/alzeimer_closed5.csv  \n",
            "  inflating: Dataset/SETD/alzeimer_closed6.csv  \n",
            "  inflating: Dataset/SETD/alzeimer_closed7.csv  \n",
            "  inflating: Dataset/SETD/alzeimer_closed8.csv  \n",
            "  inflating: Dataset/SETD/alzeimer_closed9.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files = glob.glob(\"/content/Dataset/*/*\")\n",
        "files"
      ],
      "metadata": {
        "id": "chP1TpWFPoVl",
        "outputId": "0ee2ae73-e135-46ea-e77b-533a9448f259",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/Dataset/SETC/alzeimer_open9.csv',\n",
              " '/content/Dataset/SETC/alzeimer_open6.csv',\n",
              " '/content/Dataset/SETC/alzeimer_open2.csv',\n",
              " '/content/Dataset/SETC/alzeimer_open5.csv',\n",
              " '/content/Dataset/SETC/alzeimer_open12.csv',\n",
              " '/content/Dataset/SETC/alzeimer_open11.csv',\n",
              " '/content/Dataset/SETC/alzeimer_open7.csv',\n",
              " '/content/Dataset/SETC/alzeimer_open3.csv',\n",
              " '/content/Dataset/SETC/alzeimer_open10.csv',\n",
              " '/content/Dataset/SETC/alzeimer_open4.csv',\n",
              " '/content/Dataset/SETC/alzeimer_open8.csv',\n",
              " '/content/Dataset/SETC/alzeimer_open1.csv',\n",
              " '/content/Dataset/SETD/alzeimer_closed2.csv',\n",
              " '/content/Dataset/SETD/alzeimer_closed4.csv',\n",
              " '/content/Dataset/SETD/alzeimer_closed8.csv',\n",
              " '/content/Dataset/SETD/alzeimer_closed5.csv',\n",
              " '/content/Dataset/SETD/alzeimer_closed7.csv',\n",
              " '/content/Dataset/SETD/alzeimer_closed1.csv',\n",
              " '/content/Dataset/SETD/alzeimer_closed12.csv',\n",
              " '/content/Dataset/SETD/alzeimer_closed6.csv',\n",
              " '/content/Dataset/SETD/alzeimer_closed9.csv',\n",
              " '/content/Dataset/SETD/alzeimer_closed11.csv',\n",
              " '/content/Dataset/SETD/alzeimer_closed10.csv',\n",
              " '/content/Dataset/SETD/alzeimer_closed3.csv',\n",
              " '/content/Dataset/SETB/healthy_closed11.csv',\n",
              " '/content/Dataset/SETB/healthy_closed5.csv',\n",
              " '/content/Dataset/SETB/healthy_closed4.csv',\n",
              " '/content/Dataset/SETB/healthy_closed2.csv',\n",
              " '/content/Dataset/SETB/healthy_closed8.csv',\n",
              " '/content/Dataset/SETB/healthy_closed10.csv',\n",
              " '/content/Dataset/SETB/healthy_closed3.csv',\n",
              " '/content/Dataset/SETB/healthy_closed6.csv',\n",
              " '/content/Dataset/SETB/healthy_closed12.csv',\n",
              " '/content/Dataset/SETB/healthy_closed1.csv',\n",
              " '/content/Dataset/SETB/healthy_closed7.csv',\n",
              " '/content/Dataset/SETB/healthy_closed9.csv',\n",
              " '/content/Dataset/SETA/healthy_open8.csv',\n",
              " '/content/Dataset/SETA/healthy_open12.csv',\n",
              " '/content/Dataset/SETA/healthy_open2.csv',\n",
              " '/content/Dataset/SETA/healthy_open4.csv',\n",
              " '/content/Dataset/SETA/healthy_open9.csv',\n",
              " '/content/Dataset/SETA/healthy_open3.csv',\n",
              " '/content/Dataset/SETA/healthy_open11.csv',\n",
              " '/content/Dataset/SETA/healthy_open6.csv',\n",
              " '/content/Dataset/SETA/healthy_open1.csv',\n",
              " '/content/Dataset/SETA/healthy_open7.csv',\n",
              " '/content/Dataset/SETA/healthy_open10.csv',\n",
              " '/content/Dataset/SETA/healthy_open5.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean(path):\n",
        "    df = pd.read_csv(path)\n",
        "    \n",
        "    for column in df.columns:\n",
        "        if df[column].dtype == 'object':\n",
        "            print(\"Sample : \",path,\" feature : \",column,\" is uncleaned\")\n",
        "            df[column] = pd.to_numeric(df[column], errors='coerce')\n",
        "            df[column] = df[column].fillna(method='ffill')\n",
        "            df[column] = df[column].fillna(method='bfill')\n",
        "    df = df.iloc[:1024,:]\n",
        "\n",
        "    while df.isnull().sum().values.sum() != 0:\n",
        "        print(\"Sample : \",path,\"getting cleaned\")\n",
        "        df = df.fillna(method = 'ffill')\n",
        "        df = df.fillna(method = 'bfill')\n",
        "    df.to_csv(path, index=False)\n",
        "     \n",
        "for i in files:\n",
        "    clean(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VO4V5cPYPMrD",
        "outputId": "d12c249d-5a2b-4dc4-dc29-d1ceb6b756f6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample :  /content/Dataset/SETC/alzeimer_open6.csv  feature :  0  is uncleaned\n",
            "Sample :  /content/Dataset/SETC/alzeimer_open6.csv getting cleaned\n",
            "Sample :  /content/Dataset/SETC/alzeimer_open5.csv  feature :  0  is uncleaned\n",
            "Sample :  /content/Dataset/SETC/alzeimer_open5.csv getting cleaned\n",
            "Sample :  /content/Dataset/SETC/alzeimer_open10.csv  feature :  0  is uncleaned\n",
            "Sample :  /content/Dataset/SETC/alzeimer_open10.csv getting cleaned\n",
            "Sample :  /content/Dataset/SETC/alzeimer_open8.csv  feature :  0  is uncleaned\n",
            "Sample :  /content/Dataset/SETC/alzeimer_open8.csv getting cleaned\n",
            "Sample :  /content/Dataset/SETD/alzeimer_closed12.csv  feature :  18  is uncleaned\n",
            "Sample :  /content/Dataset/SETB/healthy_closed2.csv  feature :  16  is uncleaned\n",
            "Sample :  /content/Dataset/SETB/healthy_closed6.csv  feature :  14  is uncleaned\n",
            "Sample :  /content/Dataset/SETA/healthy_open2.csv  feature :  16  is uncleaned\n",
            "Sample :  /content/Dataset/SETA/healthy_open11.csv  feature :  14  is uncleaned\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***TESTING TECHNIQUE*** : We will have a query sample of UNKNOWN CLASS which we need to predict as Healthy sample or Alzheimer sample. The query sample will be compared against stored reference samples of healthy and Alzheimer samples with the Similarity Few Shot NN trained. The intended results are: \n",
        "\n",
        "\n",
        "*   Query Sample belongs to 'Alzheimer' class if Similarity score between query sample and Alzheimer reference samples are closer to zero.\n",
        "*   Query Sample belongs to 'Healthy' class if Similarity score between query sample and healthy reference samples are closer to zero.\n",
        "\n"
      ],
      "metadata": {
        "id": "Pzw50N-MQAE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reference = [] # For Comparing Against\n",
        "query = [] # Query Samples for Detection\n",
        "for i in range(0,48,12):\n",
        "    reference += files[i:i+11]\n",
        "    query += files[i+11:i+12]"
      ],
      "metadata": {
        "id": "VMjNkCWlP0Pr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "healthy = []\n",
        "alz = []\n",
        "for afile in reference:\n",
        "    if \"healthy\" in afile:\n",
        "        healthy.append(afile)\n",
        "    elif \"alzeimer\" in afile:\n",
        "        alz.append(afile)    "
      ],
      "metadata": {
        "id": "GVYiYBD6SsXm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query Samples We will be testing are :"
      ],
      "metadata": {
        "id": "q3pRsFrSShRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nrPTioxSLLZ",
        "outputId": "7f752edc-ef2d-4904-90ab-3193feb221d6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/Dataset/SETC/alzeimer_open1.csv',\n",
              " '/content/Dataset/SETD/alzeimer_closed3.csv',\n",
              " '/content/Dataset/SETB/healthy_closed9.csv',\n",
              " '/content/Dataset/SETA/healthy_open5.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading a sample"
      ],
      "metadata": {
        "id": "ew26guUUdhwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_numeric(csv):\n",
        "    data = pd.read_csv(csv).values\n",
        "    return data\n",
        "\n",
        "def pair_up(x1,x2):\n",
        "        sample = [x1,x2]\n",
        "        if \"closed\" in x1:\n",
        "            sample.append(0)\n",
        "        elif \"open\" in x1:\n",
        "            sample.append(1) \n",
        "        if \"closed\" in x2:\n",
        "            sample.append(0)\n",
        "        elif \"open\" in x2:\n",
        "            sample.append(1)     \n",
        "\n",
        "        sample[0] = to_numeric(x1)\n",
        "        sample[1] = to_numeric(x2)\n",
        "\n",
        "        return sample "
      ],
      "metadata": {
        "id": "6Se4uU1ZTeun"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting Sample ready for Model Input"
      ],
      "metadata": {
        "id": "TziQRAFpdk_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def as_input(sample):\n",
        "    input = dict()\n",
        "    input['wave1'] = tf.cast(tf.expand_dims(sample[0],0),dtype = tf.float32)\n",
        "    input['wave2'] = tf.cast(tf.expand_dims(sample[1],0),dtype = tf.float32)\n",
        "    input['state'] = tf.cast(tf.expand_dims([sample[2],sample[3]],0),dtype = tf.float32)\n",
        "    return input"
      ],
      "metadata": {
        "id": "F-rkGk7gWURy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TESTING "
      ],
      "metadata": {
        "id": "PCcddBghdrOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_scores(afile):\n",
        "    print(\"Query Sample :\",afile)\n",
        "\n",
        "    healthy_scores = []\n",
        "    alz_scores = []\n",
        "\n",
        "    reference_tests = 3 #No of times to compare \n",
        "    \n",
        "    for ref in alz[:reference_tests]:\n",
        "        pair = pair_up(afile,ref)\n",
        "        pair = as_input(pair)\n",
        "        output = np.squeeze(model(pair)).tolist()\n",
        "        alz_scores.append(output)\n",
        "        \n",
        "    for ref in healthy[:reference_tests]:\n",
        "        pair = pair_up(afile,ref)\n",
        "        pair = as_input(pair)\n",
        "        output = np.squeeze(model(pair)).tolist()\n",
        "        healthy_scores.append(output)\n",
        "\n",
        "    a_avg,h_avg = sum(alz_scores)/3,sum(healthy_scores)/3\n",
        "\n",
        "    if a_avg > h_avg:\n",
        "        print(\"Dissimilarity Scores : \",healthy_scores)\n",
        "        print(\"Query Sample Class Predicted : Healthy Sample\")\n",
        "    else:\n",
        "        print(\"Dissimilarity Scores : \",alz_scores)\n",
        "        print(\"Query Sample Class Predicted : Alzheimer Sample\")    "
      ],
      "metadata": {
        "id": "jdUcFcQzSmjV"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for que in query:\n",
        "    print(\"-----------------------------------------------------------------\")\n",
        "    get_scores(que)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NxRHnKjbjkN",
        "outputId": "b59437aa-b3e6-413e-c8a7-753515c5fee1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------\n",
            "Query Sample : /content/Dataset/SETC/alzeimer_open1.csv\n",
            "Dissimilarity Scores :  [0.0020911688916385174, 0.008682365529239178, 0.002980213612318039]\n",
            "Query Sample Class Predicted : Alzheimer Sample\n",
            "-----------------------------------------------------------------\n",
            "Query Sample : /content/Dataset/SETD/alzeimer_closed3.csv\n",
            "Dissimilarity Scores :  [0.03581215441226959, 0.10840819031000137, 0.0709354355931282]\n",
            "Query Sample Class Predicted : Alzheimer Sample\n",
            "-----------------------------------------------------------------\n",
            "Query Sample : /content/Dataset/SETB/healthy_closed9.csv\n",
            "Dissimilarity Scores :  [0.0022117451298981905, 0.045885346829891205, 0.00997800100594759]\n",
            "Query Sample Class Predicted : Healthy Sample\n",
            "-----------------------------------------------------------------\n",
            "Query Sample : /content/Dataset/SETA/healthy_open5.csv\n",
            "Dissimilarity Scores :  [0.004654085263609886, 0.11391087621450424, 0.03120085969567299]\n",
            "Query Sample Class Predicted : Healthy Sample\n"
          ]
        }
      ]
    }
  ]
}